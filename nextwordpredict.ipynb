{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bf403ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "202d061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Abhishek commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students, like Abhishek himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.\",\n",
    "    \"In 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Abhishek remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.\",\n",
    "    \"deep learning is a branch of machine learning\",\n",
    "    \"natural language processing is a field of AI\",\n",
    "    \"AI is the future\",\n",
    "    \"I enjoy teaching AI\",\n",
    "    \"students love AI projects\",\n",
    "    \"learning new things is exciting\",\n",
    "    \"teaching AI is rewarding\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed895474",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer() \n",
    "\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56dcc880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'the',\n",
       " 3: 'is',\n",
       " 4: 'ai',\n",
       " 5: 'to',\n",
       " 6: 'ineuron',\n",
       " 7: 'in',\n",
       " 8: 'of',\n",
       " 9: 'abhishek',\n",
       " 10: 'was',\n",
       " 11: 'students',\n",
       " 12: 'learning',\n",
       " 13: 'affordable',\n",
       " 14: 'his',\n",
       " 15: 'mission',\n",
       " 16: 'over',\n",
       " 17: 'from',\n",
       " 18: 'they',\n",
       " 19: 'acquisition',\n",
       " 20: 'teaching',\n",
       " 21: 'commitment',\n",
       " 22: 'education',\n",
       " 23: \"wasn't\",\n",
       " 24: 'just',\n",
       " 25: 'business',\n",
       " 26: 'strategy—it',\n",
       " 27: \"life's\",\n",
       " 28: 'years',\n",
       " 29: 'has',\n",
       " 30: 'helped',\n",
       " 31: '1',\n",
       " 32: '5',\n",
       " 33: 'million',\n",
       " 34: '34',\n",
       " 35: 'countries',\n",
       " 36: 'providing',\n",
       " 37: 'them',\n",
       " 38: 'with',\n",
       " 39: 'skills',\n",
       " 40: 'need',\n",
       " 41: 'succeed',\n",
       " 42: \"today's\",\n",
       " 43: 'competitive',\n",
       " 44: 'job',\n",
       " 45: 'market',\n",
       " 46: 'many',\n",
       " 47: 'these',\n",
       " 48: 'like',\n",
       " 49: 'himself',\n",
       " 50: 'came',\n",
       " 51: 'disadvantaged',\n",
       " 52: 'backgrounds',\n",
       " 53: 'saw',\n",
       " 54: 'as',\n",
       " 55: 'lifeline—an',\n",
       " 56: 'opportunity',\n",
       " 57: 'rise',\n",
       " 58: 'above',\n",
       " 59: 'their',\n",
       " 60: 'circumstances',\n",
       " 61: '2022',\n",
       " 62: 'acquired',\n",
       " 63: 'by',\n",
       " 64: 'physicswallah',\n",
       " 65: 'deal',\n",
       " 66: 'worth',\n",
       " 67: '₹250',\n",
       " 68: 'crore',\n",
       " 69: 'while',\n",
       " 70: 'this',\n",
       " 71: 'significant',\n",
       " 72: 'milestone',\n",
       " 73: 'remained',\n",
       " 74: 'focused',\n",
       " 75: 'on',\n",
       " 76: 'even',\n",
       " 77: 'after',\n",
       " 78: 'continued',\n",
       " 79: 'offer',\n",
       " 80: 'some',\n",
       " 81: 'most',\n",
       " 82: 'and',\n",
       " 83: 'accessible',\n",
       " 84: 'tech',\n",
       " 85: 'courses',\n",
       " 86: 'world',\n",
       " 87: 'deep',\n",
       " 88: 'branch',\n",
       " 89: 'machine',\n",
       " 90: 'natural',\n",
       " 91: 'language',\n",
       " 92: 'processing',\n",
       " 93: 'field',\n",
       " 94: 'future',\n",
       " 95: 'i',\n",
       " 96: 'enjoy',\n",
       " 97: 'love',\n",
       " 98: 'projects',\n",
       " 99: 'new',\n",
       " 100: 'things',\n",
       " 101: 'exciting',\n",
       " 102: 'rewarding'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00c93e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'the': 2,\n",
       " 'is': 3,\n",
       " 'ai': 4,\n",
       " 'to': 5,\n",
       " 'ineuron': 6,\n",
       " 'in': 7,\n",
       " 'of': 8,\n",
       " 'abhishek': 9,\n",
       " 'was': 10,\n",
       " 'students': 11,\n",
       " 'learning': 12,\n",
       " 'affordable': 13,\n",
       " 'his': 14,\n",
       " 'mission': 15,\n",
       " 'over': 16,\n",
       " 'from': 17,\n",
       " 'they': 18,\n",
       " 'acquisition': 19,\n",
       " 'teaching': 20,\n",
       " 'commitment': 21,\n",
       " 'education': 22,\n",
       " \"wasn't\": 23,\n",
       " 'just': 24,\n",
       " 'business': 25,\n",
       " 'strategy—it': 26,\n",
       " \"life's\": 27,\n",
       " 'years': 28,\n",
       " 'has': 29,\n",
       " 'helped': 30,\n",
       " '1': 31,\n",
       " '5': 32,\n",
       " 'million': 33,\n",
       " '34': 34,\n",
       " 'countries': 35,\n",
       " 'providing': 36,\n",
       " 'them': 37,\n",
       " 'with': 38,\n",
       " 'skills': 39,\n",
       " 'need': 40,\n",
       " 'succeed': 41,\n",
       " \"today's\": 42,\n",
       " 'competitive': 43,\n",
       " 'job': 44,\n",
       " 'market': 45,\n",
       " 'many': 46,\n",
       " 'these': 47,\n",
       " 'like': 48,\n",
       " 'himself': 49,\n",
       " 'came': 50,\n",
       " 'disadvantaged': 51,\n",
       " 'backgrounds': 52,\n",
       " 'saw': 53,\n",
       " 'as': 54,\n",
       " 'lifeline—an': 55,\n",
       " 'opportunity': 56,\n",
       " 'rise': 57,\n",
       " 'above': 58,\n",
       " 'their': 59,\n",
       " 'circumstances': 60,\n",
       " '2022': 61,\n",
       " 'acquired': 62,\n",
       " 'by': 63,\n",
       " 'physicswallah': 64,\n",
       " 'deal': 65,\n",
       " 'worth': 66,\n",
       " '₹250': 67,\n",
       " 'crore': 68,\n",
       " 'while': 69,\n",
       " 'this': 70,\n",
       " 'significant': 71,\n",
       " 'milestone': 72,\n",
       " 'remained': 73,\n",
       " 'focused': 74,\n",
       " 'on': 75,\n",
       " 'even': 76,\n",
       " 'after': 77,\n",
       " 'continued': 78,\n",
       " 'offer': 79,\n",
       " 'some': 80,\n",
       " 'most': 81,\n",
       " 'and': 82,\n",
       " 'accessible': 83,\n",
       " 'tech': 84,\n",
       " 'courses': 85,\n",
       " 'world': 86,\n",
       " 'deep': 87,\n",
       " 'branch': 88,\n",
       " 'machine': 89,\n",
       " 'natural': 90,\n",
       " 'language': 91,\n",
       " 'processing': 92,\n",
       " 'field': 93,\n",
       " 'future': 94,\n",
       " 'i': 95,\n",
       " 'enjoy': 96,\n",
       " 'love': 97,\n",
       " 'projects': 98,\n",
       " 'new': 99,\n",
       " 'things': 100,\n",
       " 'exciting': 101,\n",
       " 'rewarding': 102}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f3d97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f779f970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18, 53, 6, 54, 1, 55, 56, 5, 57, 58, 59, 60]\n",
      "[9, 21]\n",
      "[9, 21, 5]\n",
      "[9, 21, 5, 13]\n",
      "[9, 21, 5, 13, 22]\n",
      "[9, 21, 5, 13, 22, 23]\n",
      "[9, 21, 5, 13, 22, 23, 24]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18, 53]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18, 53, 6]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18, 53, 6, 54]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18, 53, 6, 54, 1]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18, 53, 6, 54, 1, 55]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18, 53, 6, 54, 1, 55, 56]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18, 53, 6, 54, 1, 55, 56, 5]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18, 53, 6, 54, 1, 55, 56, 5, 57]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18, 53, 6, 54, 1, 55, 56, 5, 57, 58]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18, 53, 6, 54, 1, 55, 56, 5, 57, 58, 59]\n",
      "[9, 21, 5, 13, 22, 23, 24, 1, 25, 26, 10, 14, 27, 15, 16, 2, 28, 6, 29, 30, 16, 31, 32, 33, 11, 17, 34, 35, 36, 37, 38, 2, 39, 18, 40, 5, 41, 7, 42, 43, 44, 45, 46, 8, 47, 11, 48, 9, 49, 50, 17, 51, 52, 18, 53, 6, 54, 1, 55, 56, 5, 57, 58, 59, 60]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80, 8, 2, 81, 13, 82, 83, 84, 85, 7, 2, 86]\n",
      "[7, 61]\n",
      "[7, 61, 6]\n",
      "[7, 61, 6, 10]\n",
      "[7, 61, 6, 10, 62]\n",
      "[7, 61, 6, 10, 62, 63]\n",
      "[7, 61, 6, 10, 62, 63, 64]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80, 8]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80, 8, 2]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80, 8, 2, 81]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80, 8, 2, 81, 13]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80, 8, 2, 81, 13, 82]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80, 8, 2, 81, 13, 82, 83]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80, 8, 2, 81, 13, 82, 83, 84]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80, 8, 2, 81, 13, 82, 83, 84, 85]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80, 8, 2, 81, 13, 82, 83, 84, 85, 7]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80, 8, 2, 81, 13, 82, 83, 84, 85, 7, 2]\n",
      "[7, 61, 6, 10, 62, 63, 64, 7, 1, 65, 66, 67, 68, 69, 70, 19, 10, 1, 71, 72, 9, 73, 74, 75, 14, 15, 76, 77, 2, 19, 6, 78, 5, 79, 80, 8, 2, 81, 13, 82, 83, 84, 85, 7, 2, 86]\n",
      "[87, 12, 3, 1, 88, 8, 89, 12]\n",
      "[87, 12]\n",
      "[87, 12, 3]\n",
      "[87, 12, 3, 1]\n",
      "[87, 12, 3, 1, 88]\n",
      "[87, 12, 3, 1, 88, 8]\n",
      "[87, 12, 3, 1, 88, 8, 89]\n",
      "[87, 12, 3, 1, 88, 8, 89, 12]\n",
      "[90, 91, 92, 3, 1, 93, 8, 4]\n",
      "[90, 91]\n",
      "[90, 91, 92]\n",
      "[90, 91, 92, 3]\n",
      "[90, 91, 92, 3, 1]\n",
      "[90, 91, 92, 3, 1, 93]\n",
      "[90, 91, 92, 3, 1, 93, 8]\n",
      "[90, 91, 92, 3, 1, 93, 8, 4]\n",
      "[4, 3, 2, 94]\n",
      "[4, 3]\n",
      "[4, 3, 2]\n",
      "[4, 3, 2, 94]\n",
      "[95, 96, 20, 4]\n",
      "[95, 96]\n",
      "[95, 96, 20]\n",
      "[95, 96, 20, 4]\n",
      "[11, 97, 4, 98]\n",
      "[11, 97]\n",
      "[11, 97, 4]\n",
      "[11, 97, 4, 98]\n",
      "[12, 99, 100, 3, 101]\n",
      "[12, 99]\n",
      "[12, 99, 100]\n",
      "[12, 99, 100, 3]\n",
      "[12, 99, 100, 3, 101]\n",
      "[20, 4, 3, 102]\n",
      "[20, 4]\n",
      "[20, 4, 3]\n",
      "[20, 4, 3, 102]\n"
     ]
    }
   ],
   "source": [
    "input_sequence = [] \n",
    "\n",
    "# create n-grams for each sentence \n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    print(token_list)\n",
    "    for i in  range(1,len(token_list)):\n",
    "        ngram_seq = token_list[:i+1]\n",
    "        print(ngram_seq)\n",
    "        input_sequence.append(ngram_seq)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ecdc028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   9,  21],\n",
       "       [  0,   0,   0, ...,   9,  21,   5],\n",
       "       [  0,   0,   0, ...,  21,   5,  13],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,  20,   4],\n",
       "       [  0,   0,   0, ...,  20,   4,   3],\n",
       "       [  0,   0,   0, ...,   4,   3, 102]], dtype=int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c1ce676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  9, 21],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "76937822",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = max(len(i) for i in input_sequence)\n",
    "  = pad_sequences(input_sequence,maxlen=max_seq_len , padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3ed3a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   9,  21],\n",
       "       [  0,   0,   0, ...,   9,  21,   5],\n",
       "       [  0,   0,   0, ...,  21,   5,  13],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,  20,   4],\n",
       "       [  0,   0,   0, ...,  20,   4,   3],\n",
       "       [  0,   0,   0, ...,   4,   3, 102]], dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "670079bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input_sequence[: , :-1]  # remove last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f78ddccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0,  9],\n",
       "       [ 0,  0,  0, ...,  0,  9, 21],\n",
       "       [ 0,  0,  0, ...,  9, 21,  5],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0, 20],\n",
       "       [ 0,  0,  0, ...,  0, 20,  4],\n",
       "       [ 0,  0,  0, ..., 20,  4,  3]], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "613d6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = input_sequence[: , -1]  # remove first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26522a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21,   5,  13,  22,  23,  24,   1,  25,  26,  10,  14,  27,  15,\n",
       "        16,   2,  28,   6,  29,  30,  16,  31,  32,  33,  11,  17,  34,\n",
       "        35,  36,  37,  38,   2,  39,  18,  40,   5,  41,   7,  42,  43,\n",
       "        44,  45,  46,   8,  47,  11,  48,   9,  49,  50,  17,  51,  52,\n",
       "        18,  53,   6,  54,   1,  55,  56,   5,  57,  58,  59,  60,  61,\n",
       "         6,  10,  62,  63,  64,   7,   1,  65,  66,  67,  68,  69,  70,\n",
       "        19,  10,   1,  71,  72,   9,  73,  74,  75,  14,  15,  76,  77,\n",
       "         2,  19,   6,  78,   5,  79,  80,   8,   2,  81,  13,  82,  83,\n",
       "        84,  85,   7,   2,  86,  12,   3,   1,  88,   8,  89,  12,  91,\n",
       "        92,   3,   1,  93,   8,   4,   3,   2,  94,  96,  20,   4,  97,\n",
       "         4,  98,  99, 100,   3, 101,   4,   3, 102], dtype=int32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46ef4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = tf.keras.utils.to_categorical(y,num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ede0356c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21,   5,  13,  22,  23,  24,   1,  25,  26,  10,  14,  27,  15,\n",
       "        16,   2,  28,   6,  29,  30,  16,  31,  32,  33,  11,  17,  34,\n",
       "        35,  36,  37,  38,   2,  39,  18,  40,   5,  41,   7,  42,  43,\n",
       "        44,  45,  46,   8,  47,  11,  48,   9,  49,  50,  17,  51,  52,\n",
       "        18,  53,   6,  54,   1,  55,  56,   5,  57,  58,  59,  60,  61,\n",
       "         6,  10,  62,  63,  64,   7,   1,  65,  66,  67,  68,  69,  70,\n",
       "        19,  10,   1,  71,  72,   9,  73,  74,  75,  14,  15,  76,  77,\n",
       "         2,  19,   6,  78,   5,  79,  80,   8,   2,  81,  13,  82,  83,\n",
       "        84,  85,   7,   2,  86,  12,   3,   1,  88,   8,  89,  12,  91,\n",
       "        92,   3,   1,  93,   8,   4,   3,   2,  94,  96,  20,   4,  97,\n",
       "         4,  98,  99, 100,   3, 101,   4,   3, 102], dtype=int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d22c121",
   "metadata": {},
   "source": [
    "## building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e026a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(total_words,32),   # embedding layer\n",
    "    LSTM(64),    # LSTM layer\n",
    "    Dense(total_words,activation='softmax')   # Dense layer and to do multiclassification we uss softmax\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a24a2faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b09d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy' , optimizer='adam' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9eae471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.0054 - loss: 4.6350 \n",
      "Epoch 2/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0552 - loss: 4.6274\n",
      "Epoch 3/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.0545 - loss: 4.6189\n",
      "Epoch 4/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0406 - loss: 4.6028\n",
      "Epoch 5/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0333 - loss: 4.5703  \n",
      "Epoch 6/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0356 - loss: 4.5060\n",
      "Epoch 7/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0456 - loss: 4.4982\n",
      "Epoch 8/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0444 - loss: 4.4237  \n",
      "Epoch 9/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0372 - loss: 4.4070\n",
      "Epoch 10/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0465 - loss: 4.3470\n",
      "Epoch 11/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0593 - loss: 4.2826\n",
      "Epoch 12/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0489 - loss: 4.2622  \n",
      "Epoch 13/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0465 - loss: 4.1994\n",
      "Epoch 14/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0856 - loss: 4.1462\n",
      "Epoch 15/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0550 - loss: 4.1243\n",
      "Epoch 16/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0552 - loss: 4.0852  \n",
      "Epoch 17/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0587 - loss: 4.0164\n",
      "Epoch 18/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.0770 - loss: 3.9590\n",
      "Epoch 19/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0934 - loss: 3.8993\n",
      "Epoch 20/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1032 - loss: 3.8109\n",
      "Epoch 21/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0765 - loss: 3.8062\n",
      "Epoch 22/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.0709 - loss: 3.7887\n",
      "Epoch 23/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0900 - loss: 3.7271\n",
      "Epoch 24/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0893 - loss: 3.6997\n",
      "Epoch 25/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0878 - loss: 3.6460\n",
      "Epoch 26/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0820 - loss: 3.6994\n",
      "Epoch 27/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1043 - loss: 3.5974\n",
      "Epoch 28/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.0787 - loss: 3.5820\n",
      "Epoch 29/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.0843 - loss: 3.5518\n",
      "Epoch 30/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0507 - loss: 3.5490  \n",
      "Epoch 31/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1130 - loss: 3.4164\n",
      "Epoch 32/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1171 - loss: 3.4473\n",
      "Epoch 33/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1202 - loss: 3.4511\n",
      "Epoch 34/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1213 - loss: 3.4516\n",
      "Epoch 35/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1510 - loss: 3.3155\n",
      "Epoch 36/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1243 - loss: 3.3417\n",
      "Epoch 37/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1260 - loss: 3.2846\n",
      "Epoch 38/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1352 - loss: 3.2415\n",
      "Epoch 39/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1556 - loss: 3.2382\n",
      "Epoch 40/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1408 - loss: 3.2039\n",
      "Epoch 41/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1832 - loss: 3.1754\n",
      "Epoch 42/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1823 - loss: 3.1757\n",
      "Epoch 43/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1878 - loss: 3.1232\n",
      "Epoch 44/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1574 - loss: 3.1202\n",
      "Epoch 45/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1635 - loss: 3.0572\n",
      "Epoch 46/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1509 - loss: 3.0863\n",
      "Epoch 47/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1404 - loss: 3.0639\n",
      "Epoch 48/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1226 - loss: 3.0263\n",
      "Epoch 49/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1595 - loss: 2.9639\n",
      "Epoch 50/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2045 - loss: 2.9313\n",
      "Epoch 51/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2191 - loss: 2.9263\n",
      "Epoch 52/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1874 - loss: 2.9095\n",
      "Epoch 53/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2312 - loss: 2.8716\n",
      "Epoch 54/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1908 - loss: 2.8574\n",
      "Epoch 55/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1993 - loss: 2.8594\n",
      "Epoch 56/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2215 - loss: 2.8464\n",
      "Epoch 57/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1963 - loss: 2.7592\n",
      "Epoch 58/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2188 - loss: 2.7580\n",
      "Epoch 59/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2150 - loss: 2.7503\n",
      "Epoch 60/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2354 - loss: 2.6872\n",
      "Epoch 61/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2400 - loss: 2.6426\n",
      "Epoch 62/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2693 - loss: 2.6577\n",
      "Epoch 63/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3145 - loss: 2.6060\n",
      "Epoch 64/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3191 - loss: 2.5976\n",
      "Epoch 65/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3206 - loss: 2.6096\n",
      "Epoch 66/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.3445 - loss: 2.5296\n",
      "Epoch 67/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2904 - loss: 2.5328\n",
      "Epoch 68/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3567 - loss: 2.5147\n",
      "Epoch 69/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3959 - loss: 2.4257\n",
      "Epoch 70/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3312 - loss: 2.4563\n",
      "Epoch 71/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3495 - loss: 2.4602\n",
      "Epoch 72/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3638 - loss: 2.4321\n",
      "Epoch 73/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3695 - loss: 2.3787\n",
      "Epoch 74/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3267 - loss: 2.3797\n",
      "Epoch 75/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4062 - loss: 2.3508\n",
      "Epoch 76/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3677 - loss: 2.3281\n",
      "Epoch 77/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4019 - loss: 2.3434\n",
      "Epoch 78/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4496 - loss: 2.3038\n",
      "Epoch 79/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3528 - loss: 2.3194\n",
      "Epoch 80/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3986 - loss: 2.2324\n",
      "Epoch 81/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4092 - loss: 2.2784\n",
      "Epoch 82/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4223 - loss: 2.2209\n",
      "Epoch 83/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5372 - loss: 2.1565\n",
      "Epoch 84/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4008 - loss: 2.1859\n",
      "Epoch 85/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4912 - loss: 2.1894\n",
      "Epoch 86/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5129 - loss: 2.1306\n",
      "Epoch 87/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4834 - loss: 2.1412\n",
      "Epoch 88/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5320 - loss: 2.0846\n",
      "Epoch 89/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4944 - loss: 2.0825\n",
      "Epoch 90/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4632 - loss: 2.0825\n",
      "Epoch 91/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4717 - loss: 2.0580\n",
      "Epoch 92/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5544 - loss: 1.9792\n",
      "Epoch 93/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5520 - loss: 2.0177\n",
      "Epoch 94/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5471 - loss: 1.9993\n",
      "Epoch 95/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5412 - loss: 1.9915\n",
      "Epoch 96/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5742 - loss: 1.9058\n",
      "Epoch 97/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5871 - loss: 1.9530\n",
      "Epoch 98/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5920 - loss: 1.9299\n",
      "Epoch 99/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5970 - loss: 1.9148\n",
      "Epoch 100/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6237 - loss: 1.8826\n",
      "Epoch 101/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5584 - loss: 1.8887\n",
      "Epoch 102/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6285 - loss: 1.8502\n",
      "Epoch 103/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6403 - loss: 1.8655\n",
      "Epoch 104/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6216 - loss: 1.8260\n",
      "Epoch 105/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6331 - loss: 1.8411\n",
      "Epoch 106/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6694 - loss: 1.7657\n",
      "Epoch 107/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6520 - loss: 1.7956\n",
      "Epoch 108/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6759 - loss: 1.7744\n",
      "Epoch 109/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6792 - loss: 1.7940\n",
      "Epoch 110/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6820 - loss: 1.7621\n",
      "Epoch 111/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7229 - loss: 1.7349\n",
      "Epoch 112/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6797 - loss: 1.7066\n",
      "Epoch 113/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6783 - loss: 1.6682\n",
      "Epoch 114/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6796 - loss: 1.6457\n",
      "Epoch 115/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6857 - loss: 1.6587\n",
      "Epoch 116/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6377 - loss: 1.6912\n",
      "Epoch 117/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6978 - loss: 1.6410\n",
      "Epoch 118/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7268 - loss: 1.6199\n",
      "Epoch 119/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7339 - loss: 1.5997\n",
      "Epoch 120/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7175 - loss: 1.6009\n",
      "Epoch 121/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7629 - loss: 1.5933\n",
      "Epoch 122/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7164 - loss: 1.5679\n",
      "Epoch 123/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7359 - loss: 1.5394\n",
      "Epoch 124/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7429 - loss: 1.5575\n",
      "Epoch 125/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6178 - loss: 1.6097\n",
      "Epoch 126/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7134 - loss: 1.5422\n",
      "Epoch 127/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7622 - loss: 1.4907\n",
      "Epoch 128/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7663 - loss: 1.5209\n",
      "Epoch 129/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7635 - loss: 1.5050\n",
      "Epoch 130/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7777 - loss: 1.4968\n",
      "Epoch 131/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7668 - loss: 1.5189\n",
      "Epoch 132/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8302 - loss: 1.4283\n",
      "Epoch 133/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7975 - loss: 1.4895\n",
      "Epoch 134/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8643 - loss: 1.3876\n",
      "Epoch 135/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8235 - loss: 1.4192\n",
      "Epoch 136/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8561 - loss: 1.3970\n",
      "Epoch 137/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8661 - loss: 1.3922\n",
      "Epoch 138/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.8820 - loss: 1.3509\n",
      "Epoch 139/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8670 - loss: 1.3656\n",
      "Epoch 140/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8770 - loss: 1.3626\n",
      "Epoch 141/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8572 - loss: 1.3290\n",
      "Epoch 142/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8446 - loss: 1.3371\n",
      "Epoch 143/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8412 - loss: 1.3208\n",
      "Epoch 144/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8694 - loss: 1.3028\n",
      "Epoch 145/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8637 - loss: 1.2978\n",
      "Epoch 146/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8780 - loss: 1.2880\n",
      "Epoch 147/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8631 - loss: 1.2861\n",
      "Epoch 148/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8009 - loss: 1.3252\n",
      "Epoch 149/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8748 - loss: 1.2880\n",
      "Epoch 150/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8422 - loss: 1.2923\n",
      "Epoch 151/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8400 - loss: 1.2969\n",
      "Epoch 152/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8724 - loss: 1.2828\n",
      "Epoch 153/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8620 - loss: 1.3470\n",
      "Epoch 154/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8976 - loss: 1.3013\n",
      "Epoch 155/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9022 - loss: 1.3079\n",
      "Epoch 156/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8885 - loss: 1.2766\n",
      "Epoch 157/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9287 - loss: 1.2341\n",
      "Epoch 158/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9107 - loss: 1.2051\n",
      "Epoch 159/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9228 - loss: 1.1934\n",
      "Epoch 160/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9192 - loss: 1.2035\n",
      "Epoch 161/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9231 - loss: 1.1739\n",
      "Epoch 162/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9372 - loss: 1.1557\n",
      "Epoch 163/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9374 - loss: 1.1244\n",
      "Epoch 164/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9383 - loss: 1.1029\n",
      "Epoch 165/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9554 - loss: 1.1508\n",
      "Epoch 166/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9311 - loss: 1.0969\n",
      "Epoch 167/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9463 - loss: 1.0987\n",
      "Epoch 168/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9539 - loss: 1.0859\n",
      "Epoch 169/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9535 - loss: 1.0940\n",
      "Epoch 170/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9509 - loss: 1.0581\n",
      "Epoch 171/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9415 - loss: 1.0779\n",
      "Epoch 172/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9446 - loss: 1.0732\n",
      "Epoch 173/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9368 - loss: 1.0396\n",
      "Epoch 174/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9279 - loss: 1.0362\n",
      "Epoch 175/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9144 - loss: 1.0506\n",
      "Epoch 176/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9148 - loss: 1.0402\n",
      "Epoch 177/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9698 - loss: 1.0051\n",
      "Epoch 178/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9674 - loss: 0.9639\n",
      "Epoch 179/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9607 - loss: 0.9407\n",
      "Epoch 180/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9635 - loss: 0.9670\n",
      "Epoch 181/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9368 - loss: 0.9253\n",
      "Epoch 182/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9633 - loss: 0.9481\n",
      "Epoch 183/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9548 - loss: 0.9725\n",
      "Epoch 184/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9657 - loss: 0.9358\n",
      "Epoch 185/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9848 - loss: 0.8944\n",
      "Epoch 186/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9652 - loss: 0.8959\n",
      "Epoch 187/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9841 - loss: 0.8917\n",
      "Epoch 188/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9678 - loss: 0.9007\n",
      "Epoch 189/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9678 - loss: 0.8665\n",
      "Epoch 190/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9872 - loss: 0.8700\n",
      "Epoch 191/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9859 - loss: 0.8616\n",
      "Epoch 192/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9698 - loss: 0.8691\n",
      "Epoch 193/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9837 - loss: 0.8555\n",
      "Epoch 194/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9872 - loss: 0.8041\n",
      "Epoch 195/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9828 - loss: 0.8334\n",
      "Epoch 196/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9733 - loss: 0.8051\n",
      "Epoch 197/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9789 - loss: 0.8110\n",
      "Epoch 198/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9813 - loss: 0.8081\n",
      "Epoch 199/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9681 - loss: 0.8299\n",
      "Epoch 200/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9841 - loss: 0.7839\n",
      "Epoch 201/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9750 - loss: 0.7979\n",
      "Epoch 202/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9815 - loss: 0.7753\n",
      "Epoch 203/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9872 - loss: 0.7576\n",
      "Epoch 204/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9839 - loss: 0.7615\n",
      "Epoch 205/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9735 - loss: 0.7626\n",
      "Epoch 206/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9868 - loss: 0.7653\n",
      "Epoch 207/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9946 - loss: 0.7253\n",
      "Epoch 208/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9976 - loss: 0.7310\n",
      "Epoch 209/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9868 - loss: 0.7388\n",
      "Epoch 210/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9963 - loss: 0.7433\n",
      "Epoch 211/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9946 - loss: 0.7017\n",
      "Epoch 212/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9865 - loss: 0.7100\n",
      "Epoch 213/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9865 - loss: 0.7026\n",
      "Epoch 214/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9733 - loss: 0.7038\n",
      "Epoch 215/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9776 - loss: 0.6979\n",
      "Epoch 216/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9733 - loss: 0.7296\n",
      "Epoch 217/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9785 - loss: 0.6536\n",
      "Epoch 218/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9854 - loss: 0.6622\n",
      "Epoch 219/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9659 - loss: 0.6980\n",
      "Epoch 220/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9659 - loss: 0.7353\n",
      "Epoch 221/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9622 - loss: 0.7214\n",
      "Epoch 222/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9735 - loss: 0.6909\n",
      "Epoch 223/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9883 - loss: 0.6503\n",
      "Epoch 224/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9865 - loss: 0.6386\n",
      "Epoch 225/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9963 - loss: 0.6650\n",
      "Epoch 226/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9946 - loss: 0.6642\n",
      "Epoch 227/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9946 - loss: 0.6080\n",
      "Epoch 228/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9891 - loss: 0.6082\n",
      "Epoch 229/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9891 - loss: 0.6160\n",
      "Epoch 230/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9813 - loss: 0.6142\n",
      "Epoch 231/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9831 - loss: 0.5985\n",
      "Epoch 232/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9883 - loss: 0.5941\n",
      "Epoch 233/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9891 - loss: 0.5775\n",
      "Epoch 234/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9787 - loss: 0.5652\n",
      "Epoch 235/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9813 - loss: 0.5702\n",
      "Epoch 236/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9813 - loss: 0.5541\n",
      "Epoch 237/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9920 - loss: 0.5532\n",
      "Epoch 238/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9946 - loss: 0.5310\n",
      "Epoch 239/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9946 - loss: 0.5137\n",
      "Epoch 240/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9963 - loss: 0.5326\n",
      "Epoch 241/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9920 - loss: 0.5432\n",
      "Epoch 242/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9963 - loss: 0.5247\n",
      "Epoch 243/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9920 - loss: 0.5254\n",
      "Epoch 244/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9963 - loss: 0.4978\n",
      "Epoch 245/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9868 - loss: 0.4988\n",
      "Epoch 246/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9868 - loss: 0.5209\n",
      "Epoch 247/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9976 - loss: 0.4884\n",
      "Epoch 248/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9963 - loss: 0.4897\n",
      "Epoch 249/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.4839\n",
      "Epoch 250/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.4909\n",
      "Epoch 251/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.4862\n",
      "Epoch 252/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.4630\n",
      "Epoch 253/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.4477\n",
      "Epoch 254/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.4672\n",
      "Epoch 255/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.4454\n",
      "Epoch 256/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.4571\n",
      "Epoch 257/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.4528\n",
      "Epoch 258/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.4418\n",
      "Epoch 259/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.4360\n",
      "Epoch 260/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.4366\n",
      "Epoch 261/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.4322\n",
      "Epoch 262/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.4408\n",
      "Epoch 263/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.4116\n",
      "Epoch 264/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.4300\n",
      "Epoch 265/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.4121\n",
      "Epoch 266/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.3944\n",
      "Epoch 267/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.3942\n",
      "Epoch 268/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.4239\n",
      "Epoch 269/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.3923\n",
      "Epoch 270/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.3954\n",
      "Epoch 271/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.3996\n",
      "Epoch 272/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.4081\n",
      "Epoch 273/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.3932\n",
      "Epoch 274/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.3748\n",
      "Epoch 275/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.3752\n",
      "Epoch 276/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.3741\n",
      "Epoch 277/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.3566\n",
      "Epoch 278/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.3643\n",
      "Epoch 279/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.3564\n",
      "Epoch 280/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.3550\n",
      "Epoch 281/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.3652\n",
      "Epoch 282/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.3394\n",
      "Epoch 283/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.3312\n",
      "Epoch 284/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.3471\n",
      "Epoch 285/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.3300\n",
      "Epoch 286/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.3252\n",
      "Epoch 287/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.3257\n",
      "Epoch 288/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.3134\n",
      "Epoch 289/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.3271\n",
      "Epoch 290/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.3331\n",
      "Epoch 291/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.3098\n",
      "Epoch 292/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.3118\n",
      "Epoch 293/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.3180\n",
      "Epoch 294/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.3147\n",
      "Epoch 295/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.3058\n",
      "Epoch 296/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.2987\n",
      "Epoch 297/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.2925\n",
      "Epoch 298/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.2970\n",
      "Epoch 299/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.2890\n",
      "Epoch 300/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.2974\n",
      "Epoch 301/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.2894\n",
      "Epoch 302/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.2887\n",
      "Epoch 303/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.2892\n",
      "Epoch 304/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.2790\n",
      "Epoch 305/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.2840\n",
      "Epoch 306/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.2598\n",
      "Epoch 307/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.2762\n",
      "Epoch 308/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.2617\n",
      "Epoch 309/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.2648\n",
      "Epoch 310/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.2607\n",
      "Epoch 311/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.2610\n",
      "Epoch 312/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.2643\n",
      "Epoch 313/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.2489\n",
      "Epoch 314/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.2522\n",
      "Epoch 315/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.2500\n",
      "Epoch 316/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.2462\n",
      "Epoch 317/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.2476\n",
      "Epoch 318/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.2501\n",
      "Epoch 319/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.2395\n",
      "Epoch 320/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.2342\n",
      "Epoch 321/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.2365\n",
      "Epoch 322/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.2326\n",
      "Epoch 323/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.2417\n",
      "Epoch 324/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2353\n",
      "Epoch 325/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.2360\n",
      "Epoch 326/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.2246\n",
      "Epoch 327/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.2238\n",
      "Epoch 328/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.2254\n",
      "Epoch 329/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.2235\n",
      "Epoch 330/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.2185\n",
      "Epoch 331/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.2152\n",
      "Epoch 332/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.2166\n",
      "Epoch 333/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.2137\n",
      "Epoch 334/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.2083\n",
      "Epoch 335/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.2174\n",
      "Epoch 336/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.2128\n",
      "Epoch 337/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1989\n",
      "Epoch 338/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.2031\n",
      "Epoch 339/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.2002\n",
      "Epoch 340/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.2009\n",
      "Epoch 341/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.1986\n",
      "Epoch 342/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.2007\n",
      "Epoch 343/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.1946\n",
      "Epoch 344/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.1953\n",
      "Epoch 345/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1895\n",
      "Epoch 346/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.1910\n",
      "Epoch 347/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.1926\n",
      "Epoch 348/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.1805\n",
      "Epoch 349/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.1845\n",
      "Epoch 350/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1821\n",
      "Epoch 351/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.1795\n",
      "Epoch 352/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.1776\n",
      "Epoch 353/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1787\n",
      "Epoch 354/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.1751\n",
      "Epoch 355/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1725\n",
      "Epoch 356/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1801\n",
      "Epoch 357/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1789\n",
      "Epoch 358/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.1713\n",
      "Epoch 359/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.1691\n",
      "Epoch 360/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.1686\n",
      "Epoch 361/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.1610\n",
      "Epoch 362/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1692\n",
      "Epoch 363/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.1575\n",
      "Epoch 364/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.1631\n",
      "Epoch 365/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1607\n",
      "Epoch 366/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.1540\n",
      "Epoch 367/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.1580\n",
      "Epoch 368/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.1566\n",
      "Epoch 369/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.1555\n",
      "Epoch 370/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.1606\n",
      "Epoch 371/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.1572\n",
      "Epoch 372/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.1552\n",
      "Epoch 373/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1467\n",
      "Epoch 374/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.1489\n",
      "Epoch 375/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.1483\n",
      "Epoch 376/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.1521\n",
      "Epoch 377/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.1439\n",
      "Epoch 378/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.1428\n",
      "Epoch 379/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.1423\n",
      "Epoch 380/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.1418\n",
      "Epoch 381/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.1469\n",
      "Epoch 382/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.1342\n",
      "Epoch 383/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.1329\n",
      "Epoch 384/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.1414\n",
      "Epoch 385/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.1360\n",
      "Epoch 386/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.1368\n",
      "Epoch 387/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1375\n",
      "Epoch 388/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1361\n",
      "Epoch 389/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1368\n",
      "Epoch 390/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.1285\n",
      "Epoch 391/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1280\n",
      "Epoch 392/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1344\n",
      "Epoch 393/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1331\n",
      "Epoch 394/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1274\n",
      "Epoch 395/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.1261\n",
      "Epoch 396/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1224\n",
      "Epoch 397/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.1269\n",
      "Epoch 398/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.1256\n",
      "Epoch 399/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.1239\n",
      "Epoch 400/400\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.1235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14620c460>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=400,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79931346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'the': 2,\n",
       " 'is': 3,\n",
       " 'ai': 4,\n",
       " 'to': 5,\n",
       " 'ineuron': 6,\n",
       " 'in': 7,\n",
       " 'of': 8,\n",
       " 'abhishek': 9,\n",
       " 'was': 10,\n",
       " 'students': 11,\n",
       " 'learning': 12,\n",
       " 'affordable': 13,\n",
       " 'his': 14,\n",
       " 'mission': 15,\n",
       " 'over': 16,\n",
       " 'from': 17,\n",
       " 'they': 18,\n",
       " 'acquisition': 19,\n",
       " 'teaching': 20,\n",
       " 'commitment': 21,\n",
       " 'education': 22,\n",
       " \"wasn't\": 23,\n",
       " 'just': 24,\n",
       " 'business': 25,\n",
       " 'strategy—it': 26,\n",
       " \"life's\": 27,\n",
       " 'years': 28,\n",
       " 'has': 29,\n",
       " 'helped': 30,\n",
       " '1': 31,\n",
       " '5': 32,\n",
       " 'million': 33,\n",
       " '34': 34,\n",
       " 'countries': 35,\n",
       " 'providing': 36,\n",
       " 'them': 37,\n",
       " 'with': 38,\n",
       " 'skills': 39,\n",
       " 'need': 40,\n",
       " 'succeed': 41,\n",
       " \"today's\": 42,\n",
       " 'competitive': 43,\n",
       " 'job': 44,\n",
       " 'market': 45,\n",
       " 'many': 46,\n",
       " 'these': 47,\n",
       " 'like': 48,\n",
       " 'himself': 49,\n",
       " 'came': 50,\n",
       " 'disadvantaged': 51,\n",
       " 'backgrounds': 52,\n",
       " 'saw': 53,\n",
       " 'as': 54,\n",
       " 'lifeline—an': 55,\n",
       " 'opportunity': 56,\n",
       " 'rise': 57,\n",
       " 'above': 58,\n",
       " 'their': 59,\n",
       " 'circumstances': 60,\n",
       " '2022': 61,\n",
       " 'acquired': 62,\n",
       " 'by': 63,\n",
       " 'physicswallah': 64,\n",
       " 'deal': 65,\n",
       " 'worth': 66,\n",
       " '₹250': 67,\n",
       " 'crore': 68,\n",
       " 'while': 69,\n",
       " 'this': 70,\n",
       " 'significant': 71,\n",
       " 'milestone': 72,\n",
       " 'remained': 73,\n",
       " 'focused': 74,\n",
       " 'on': 75,\n",
       " 'even': 76,\n",
       " 'after': 77,\n",
       " 'continued': 78,\n",
       " 'offer': 79,\n",
       " 'some': 80,\n",
       " 'most': 81,\n",
       " 'and': 82,\n",
       " 'accessible': 83,\n",
       " 'tech': 84,\n",
       " 'courses': 85,\n",
       " 'world': 86,\n",
       " 'deep': 87,\n",
       " 'branch': 88,\n",
       " 'machine': 89,\n",
       " 'natural': 90,\n",
       " 'language': 91,\n",
       " 'processing': 92,\n",
       " 'field': 93,\n",
       " 'future': 94,\n",
       " 'i': 95,\n",
       " 'enjoy': 96,\n",
       " 'love': 97,\n",
       " 'projects': 98,\n",
       " 'new': 99,\n",
       " 'things': 100,\n",
       " 'exciting': 101,\n",
       " 'rewarding': 102}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c098957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(seed_text, num_words=5):\n",
    "    for _ in range(num_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_seq_len - 1, padding='pre')\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        next_word_index = np.argmax(predicted)\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == next_word_index:\n",
    "                seed_text += ' ' + word\n",
    "                break\n",
    "    return seed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8832dd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language is   a field of ai is'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(\"natural language is  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb605604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9e67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b6dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cb086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fec711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpdemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
